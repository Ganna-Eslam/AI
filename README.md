Machine Learning

1- Data Analysis                                                                                                                                                                              
2- Visualization                                                                                                                                                                              
3- Data Preprocessing                                                                                                                                                                         
4- Encoding                                                                                                                                                                                   
4 - Scaling                                                                                                                                                                                   
5- UnBalanced Data Processing (using SMOTE)                                                                                                                                                   
6 - Machine Learning Models                                                                                                                                                                   
    1.Logistic Regression                                                                                                                                                                                                                                                                                                                                        
    2.Decision Tree                                                                                                                                                                               
    3.Random Forest                                                                                                                                                                                    
    4.SVM                                                                                                                                                                                               
    5.KNN                                                                                                                                                                                                
7- Deep Learning Models                                                                                                                                                                                       
8- Comparasion Between Models                                                                                                                                                                                  
8- Fine tuning (using RandomSearch)                                                                                                                                                                              


Deep Learning 

ðŸ”¹ 1. Multimodal Fusion for COVID-19 Classification
â€‹Goal: To build a robust classification model for COVID-19 detection by integrating features from multiple data sources.
â€‹Data: Multimodal dataset including CXR (Chest X-Ray) images, CT scans, and Cough Sound spectrograms.
â€‹Methodology: Compared Early Fusion and Intermediate Fusion strategies. Applied Transfer Learning using pre-trained VGG16 and ResNet50 models as feature extractors.
â€‹Best Results (Intermediate Fusion): Achieved a Validation Accuracy of 95.70% (0.95703).
â€‹ðŸ”¹ 2. Arabic Sentiment Analysis (RNN, LSTM, Bi-LSTM)
â€‹Goal: To classify the sentiment (Positive/Negative) of Arabic tweets.
â€‹Data & Preprocessing: Used the Arabic Sentiment Twitter Corpus from Kaggle. Preprocessing involved comprehensive cleaning (URL/mention/hashtag/digit removal), punctuation stripping, and Arabic stop-words removal.
â€‹Models: Implemented and compared three Recurrent Neural Network (RNN) architectures: SimpleRNN, LSTM, and Bidirectional LSTM (Bi-LSTM).
â€‹Best Results:
â€‹SimpleRNN Accuracy: 64.17% (0.64178)
â€‹Bi-LSTM Accuracy (Best): 93.33% (0.9333)
â€‹ðŸ”¹ 3. Abstractive Summarization using Seq2Seq with Attention
â€‹Goal: To generate concise, abstractive summaries from source texts.
â€‹Architecture: Developed a Sequence-to-Sequence (Seq2Seq) model using an Encoder-Decoder architecture.
â€‹Models/Layers: Leveraged LSTM layers for both the Encoder (encoder_lstm) and Decoder (decoder_lstm). The model was enhanced with a custom Attention Mechanism to improve output quality.
â€‹Metrics (ROUGE F1):
â€‹ROUGE-1 F1: 0.4037
â€‹ROUGE-2 F1: 0.2521
â€‹ROUGE-L F1: 0.3703
â€‹ðŸ”¹ 4. Generative Adversarial Network (GAN) for Abstract Art
â€‹Goal: To train a model capable of generating novel, high-quality Abstract Art images.
â€‹Data & Image Size: Used the Abstract Art Gallery dataset, with images processed to 28x28 pixels.
â€‹Architecture: Standard GAN with coupled Generator and Discriminator networks.
â€‹Generator: Used Conv2DTranspose layers to upscale the latent noise vector into an image.
â€‹Discriminator: Used Conv2D layers with LeakyReLU and BatchNormalization to classify images as real or generated.


Computer Vision 


ðŸ”¹ 1. Brain Tumor Segmentation â€“ LGG MRI (U-Net)
â€‹Goal: Developed and trained an Image Segmentation model to accurately delineate tumor boundaries (masks) in Low-Grade Glioma (LGG) MRI scans.
â€‹Methodology: Utilized the U-Net architecture (built with TensorFlow/Keras and Adamax optimizer) on the lgg-mri-segmentation dataset.
â€‹Results: The model achieved strong performance on the test set:
â€‹Dice Coefficient: 0.8959
â€‹IoU Coefficient: 0.8249


â€‹ðŸ”¹ 2. Traffic Sign Object Detection (YOLOv12)
â€‹Goal: Trained a high-accuracy Object Detection model to identify traffic signs in various environments.
â€‹Methodology: Employed the YOLOv12 architecture using the Ultralytics framework.
â€‹Dataset: placas-transito (Traffic Signs dataset).
â€‹Results: The model demonstrated high prediction efficiency:
â€‹mAP50: 0.9161
â€‹mAP50-95: 0.7441


â€‹ðŸ”¹ 3. Static Hand Gesture Recognition Pipeline
â€‹Goal: Developed an end-to-end pipeline for recognizing static hand gestures from video frames.
â€‹Methodology:
â€‹Feature Extraction: Used MediaPipe Hands to extract 3D landmarks for a 30-frame sequence.
â€‹Classification: Trained a Logistic Regression model on the extracted feature vectors for real-time gesture classification.


â€‹ðŸ”¹ 4. Real-Time Face Recognition System
â€‹Goal: Implemented a complete, robust system for face detection, recognition, and tracking in live video streams (Real-Time).
â€‹Key Components:
â€‹High-Precision Detection: Achieved using the MTCNN network.
â€‹Deep Embedding: Used OpenFace to generate unique 128D face embeddings for identity verification.
â€‹Robust Tracking: Integrated ByteTrack for stable, multi-object tracking of faces within the video stream.


â€‹ðŸ”¹ 5. Multi-Task NLP Pipeline (Hugging Face & Gemini API)
â€‹Goal: Built an automated, multi-stage pipeline for processing and analyzing audio and text content, leveraging advanced pre-trained models.
â€‹Models Used:
â€‹Automatic Speech Recognition (ASR): Utilized the specialized MohamedRashad/Arabic-Whisper-CodeSwitching-Edition model for accurate Arabic transcription.
â€‹Translation: Used the large facebook/nllb-200-distilled-600M model for high-quality translation (Arabic to English).
â€‹Advanced Correction & Summarization: Integrated the Gemini API with the gemini-2.5-flash model to perform advanced text correction and prepare for summarization of the translated content.




